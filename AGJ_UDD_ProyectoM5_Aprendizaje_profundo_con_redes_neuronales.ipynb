{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aguiraldes94/Proyecto-Bootcamp/blob/main/AGJ_UDD_ProyectoM5_Aprendizaje_profundo_con_redes_neuronales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWVOeTCLzinO"
      },
      "source": [
        "## Bootcamp: Ciencia de Datos e Inteligencia Artificial\n",
        "## Proyecto del Módulo 5: Aprendizaje profundo con redes neuronales\n",
        "¡Hola, qué gusto que estés a un paso de obtener tu insignia del módulo 5! Aquí pondrás en juego las habilidades y conocimientos que has practicado a lo largo de estas semanas.\n",
        "\n",
        "Lee el proyecto y revisa con cuidado cada una de las instrucciones. Procura plasmar todo tu potencial para que concluyas tu proyecto de manera exitosa.\n",
        "\n",
        "¡Éxito!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LJoroXti_C8"
      },
      "source": [
        "# Objetivos\n",
        "- Aplicarás los conocimientos que has adquirido sobre redes neuronales a contextos de la vida real.\n",
        "- Puntuarás la precisión y valor de los modelos creados.\n",
        "- Generarás gráficas que muestren la evolución de la precisión de los modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FIZjDqgjC0e"
      },
      "source": [
        "> NOTA: El modelo se entrena en inglés, así que si quieres traducir estas noticias para comprenderlas mejor te puedes apoyar en herramientas como Google Translate, pero recuerda usar el texto en inglés para tu modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaMuRUUAsXf2"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIXkMjG4zm48"
      },
      "source": [
        "\n",
        "\n",
        "# Parte 1\n",
        "\n",
        "La propagación de *fake news* o noticias falsas se incrementó a partir de la pandemia por COVID-19. Estas son un problema alarmante porque hacen que las personas realicen actividades que normalmente no llevarían a cabo o que actúen de manera caótica. Un ejemplo es [-> esta noticia <-](https://drive.google.com/file/d/1PrfN83Fm1ib5mHYN6SULVe9CJVECUNn2/view?usp=share_link), en la que se relata cómo notas falsas acerca del daño que ocasiona la 5G al cuerpo provocaron que muchas personas en el Reino Unido quemaran torres de telecomunicaciones aun sin ser estas de 5G.\n",
        "\n",
        "A ti, como persona experta en redes neuronales, te han encargado hacer un predetector de noticias falsas para los *fact-checker* del mundo.\n",
        "\n",
        "Para realizarlo, tienes a tu disposición el siguiente *dataset*: https://www.kaggle.com/datasets/saurabhshahane/fake-news-classification\n",
        "\n",
        "## Criterios de evaluación\n",
        "- Utiliza Keras para entrenar un modelo de *Deep Learning* que ayude a detectar una noticia falsa. Recuerda hacer la limpieza de datos y el análisis exploratorio correspondiente para obtener el puntaje completo (2 puntos).\n",
        "  - Pista: Revisa esto -> https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
        "- Determina el número de épocas a usar y explica por escrito por qué llegaste a esta conclusión. Si no hay explicación, no hay un punto (2 puntos).\n",
        "- Calcula la precisión y pérdida del modelo (1 punto) y grafícalo a través de las épocas (1 punto).\n",
        "- Prueba tu modelo con esta noticia falsa: https://www.breitbart.com/politics/2016/09/10/exposed-fbi-director-james-comeys-clinton-foundation-connection/\n",
        "- Prueba tu modelo con esta noticia verdadera: https://www.washingtonpost.com/sports/2022/11/14/world-cup-female-referee-kathryn-nesbitt/ (2 puntos por ambas comprobaciones).\n",
        "\n",
        "## Punto extra\n",
        "- Usa PyTorch para el entrenamiento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvWf7oVUfZza"
      },
      "source": [
        "# 1 .  Importación de Librería y preparación de Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Eim1MOrfZHj"
      },
      "outputs": [],
      "source": [
        "# --- Base y Visualización ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "import warnings\n",
        "\n",
        "# --- Machine Learning Clásico (Línea Base) ---\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# --- Deep Learning (Keras/TensorFlow) ---\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# --- Punto Extra (PyTorch/Hugging Face/PEFT) ---\n",
        "import torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, TrainingArguments, Trainer\n",
        "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
        "from peft import LoraConfig, get_peft_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9jqRZL1fmPy"
      },
      "outputs": [],
      "source": [
        "# Para que tu modelo BERT (que está en PyTorch) y sus datos funcionen en la GPU, deben ser movidos explícitamente a ese dispositivo.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R40VJ1gZil2h"
      },
      "outputs": [],
      "source": [
        "#No es necesario para la primera parte con Keras , pero si para BERT\n",
        "!pip install evaluate\n",
        "\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZktLXnCsVlB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8Vyd0MLtveH"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/WELFake_Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-gRT4M7dTkq"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRCEGd2Lg7wi"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ODV9ZoriS_i"
      },
      "outputs": [],
      "source": [
        "# Contar el número de filas antes de la eliminación\n",
        "rows_before_drop = len(data)\n",
        "\n",
        "# Eliminar filas duplicadas\n",
        "# duplicated(): Identifica todas las filas que son copias exactas de filas anteriores.\n",
        "# drop_duplicates(inplace=True): Elimina esas filas duplicadas y actualiza el DataFrame 'data'.\n",
        "data.drop_duplicates(inplace=True)\n",
        "\n",
        "# Contar el número de filas después de la eliminación\n",
        "rows_after_drop = len(data)\n",
        "\n",
        "# 4. Mostrar el informe\n",
        "rows_dropped = rows_before_drop - rows_after_drop\n",
        "print(f\"Filas totales antes de eliminar duplicados: {rows_before_drop}\")\n",
        "print(f\"Número de filas duplicadas eliminadas: {rows_dropped}\")\n",
        "print(f\"Filas restantes en el DataFrame: {rows_after_drop}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkMHWSIzjXP5"
      },
      "outputs": [],
      "source": [
        "data.drop('Unnamed: 0',axis=1,inplace=True)\n",
        "data.rename(columns={'label':'labels'},inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s-x4EG8jYlR"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZV9NNhtjeSS"
      },
      "outputs": [],
      "source": [
        "# Null values\n",
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awEKe-V_jgFZ"
      },
      "outputs": [],
      "source": [
        "def plot_nulls(data,title,x_axis_label,y_axis_label):\n",
        "\n",
        "    # Number of nulls for each column\n",
        "    data_nulls = (data.apply(lambda x:x.isnull().value_counts()).T[True]/len(data)*100).reset_index(name='count')\n",
        "\n",
        "    sns.barplot(data_nulls,x=\"index\",y=\"count\")\n",
        "    plt.title(title,fontsize=20)\n",
        "    plt.xlabel(x_axis_label,fontsize=13)\n",
        "    plt.ylabel(y_axis_label,fontsize=13)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_nulls(data,\"Valores Nulos\",'Tipos','% de nulos por columna')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7o3bF5njjcB"
      },
      "outputs": [],
      "source": [
        "data.dropna(axis=0,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yglXReKjl1h"
      },
      "outputs": [],
      "source": [
        "# Valores duplicados\n",
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8rkkWWSjn4R"
      },
      "outputs": [],
      "source": [
        "data.drop_duplicates(inplace=True)\n",
        "\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2E9nbvTejrJ5"
      },
      "outputs": [],
      "source": [
        "# Reorganizar aleatoriamente el dataset\n",
        "data = data.sample(frac=1,random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRP8tRj9jsoZ"
      },
      "source": [
        "# 2 . Exploración de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsnm4iGJj6ei"
      },
      "source": [
        "Se puede ver levemente desbalanceado, mas no es una diferencia significativa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DgcoJQgkFiS"
      },
      "source": [
        "## 2.1 Analisis de Tokens (Fragmentos de Palabras) en titulos y texto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHN1UOkLj4NJ"
      },
      "outputs": [],
      "source": [
        "# Nota Importante sobre la Estimación de Tokens:\n",
        "# Se utiliza el factor de 1.5 veces el número de palabras (len(x.split())) porque un tokenizador avanzado (como el de BERT, o incluso Keras/BPE) a menudo divide una sola palabra en 1.2 a 2.0 subtokens.\n",
        "#Usar 1.5 es una buena estimación para la longitud de secuencia (MAX_LEN) requerida.\n",
        "\n",
        "# 1. Cálculo de la Longitud Estimada de Tokens\n",
        "\n",
        "# Estima los tokens para la columnamultiplicando el número de palabras por 1.5.\n",
        "title_tokens = data['title'].apply(lambda x: len(x.split()) * 1.5)\n",
        "text_tokens = data['text'].apply(lambda x: len(x.split()) * 1.5)\n",
        "\n",
        "# 2. Creación de la Figura y Subgráficos\n",
        "\n",
        "# Crea una figura con dos subgráficos (una fila, dos columnas) para comparar Título y Texto.\n",
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 6))\n",
        "\n",
        "# 3. Gráfico para Tokens en Títulos (ax1). Grafico 1.\n",
        "\n",
        "ax1 = sns.histplot(title_tokens, ax=ax1, bins=20)\n",
        "ax1.set_xlabel('N° Tokens Estimado')\n",
        "ax1.set_title(\"Tokens en Títulos\", fontsize=20)\n",
        "ax1.set_xlim(0, 40)\n",
        "\n",
        "# 4. Gráfico para Tokens en Texto (ax2). Grafico 2.\n",
        "\n",
        "ax2 = sns.histplot(text_tokens, ax=ax2, bins=200)\n",
        "ax2.set_xlabel('N° Tokens Estimado')\n",
        "ax2.set_title(\"Tokens en Texto\", fontsize=20)\n",
        "ax2.set_xlim(0, 3000)\n",
        "\n",
        "# 5. Mostrar el Gráfico\n",
        "\n",
        "# Asegura que los títulos y etiquetas no se superpongan.\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Cálculo de la Longitud Estimada de Tokens (Factor 1.5)\n",
        "# Multiplicamos por 1.5 para estimar la longitud real después de la tokenización.\n",
        "title_token_counts = data['title'].apply(lambda x: len(x.split()) * 1.5)\n",
        "text_token_counts = data['text'].apply(lambda x: len(x.split()) * 1.5)\n",
        "\n",
        "# 2. Generación y Formato del Análisis Descriptivo\n",
        "# Utilizamos describe() para obtener las estadísticas y luego aplicamos el formato.\n",
        "\n",
        "# --- Títulos ---\n",
        "title_stats = title_token_counts.describe()\n",
        "print(\"\\n--- Estadísticas Descriptivas de Tokens en Títulos ---\")\n",
        "# Imprime la tabla con el formato de 2 decimales\n",
        "print(title_stats.to_string(float_format=\"%.2f\"))\n",
        "\n",
        "# --- Textos ---\n",
        "text_stats = text_token_counts.describe()\n",
        "print(\"\\n--- Estadísticas Descriptivas de Tokens en Textos ---\")\n",
        "# Imprime la tabla con el formato de 2 decimales\n",
        "print(text_stats.to_string(float_format=\"%.2f\"))\n",
        "\n",
        "# 3. Extracción de Percentiles Clave para MAX_LEN (con 2 decimales)\n",
        "\n",
        "p90_titles = title_token_counts.quantile(0.90)\n",
        "p95_titles = title_token_counts.quantile(0.95)\n",
        "\n",
        "print(f\"\\n--- Posible candidato a Decisión de MAX_LEN  ---\")\n",
        "print(f\"El 90% de los títulos son más cortos que: {p90_titles:.2f} tokens.\")\n",
        "print(f\"El 95% de los títulos son más cortos que: {p95_titles:.2f} tokens.\")"
      ],
      "metadata": {
        "id": "rzDmuxPulBmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfvV5lACumaW"
      },
      "source": [
        "Algo que no es novedad, pero para analizar, existe una cantidad enorme de tokens en el texto comparado con los titulos.  En promedio un texto tiene 820 tokens mientras que un titulo solo 18. Mientras que la mediana de un texto tiene 606 y la de un titulo cerca de 16.\n",
        "\n",
        "Con esta información podremos tomar varias decisiones, dentro de estas justicar por qué usar solo los titulos y el tamaño del titulo (tokens) que necesitara el modelo como input de entrada en su prueba.\n",
        "\n",
        "El uso de texto para poder analizar si es fake o real la noticia sería muy costoso a nivel computacional. Vimos que el texto promedio tiene más de 800 tokens en promedio y el más largo cerca de 36.000. Esto utilizará mucha memoria en nuestra GPU.\n",
        "\n",
        "En cambio en los titulos, se pude analizar que el token promedio es de 18 y el más largo casi 110. Si quisieramos descartar el 10% por más, solo usariamos las noticias con un texto menor a los 26 tokens (MAX_LEN). Sin embargo analizaremos las razones en unos codigos más de porque es más eficiente usar uno menor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZuLfVMfmr15"
      },
      "source": [
        "## 2.2 Promedio de palabras en los titulos de noticias reales y falsas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BC6z0tUm0cJ"
      },
      "outputs": [],
      "source": [
        "# ---  Preparación de Datos ---\n",
        "\n",
        "# Mapeo de Etiquetas Legibles\n",
        "news_map = {1:'real', 0:'fake'}\n",
        "data['label_names'] = data['labels'].map(news_map)\n",
        "\n",
        "# Calcular la longitud de palabras para los títulos falsos:\n",
        "# Localiza las filas donde 'labels' es 0 (fake) y aplica la función lambda para contar palabras.\n",
        "fake_title = data.loc[data.labels == 0]['title'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Calcular la longitud de palabras para los títulos reales:\n",
        "# Localiza las filas donde 'labels' es 1 (real) y aplica la función lambda para contar palabras.\n",
        "real_title = data.loc[data.labels == 1]['title'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Crear la columna auxiliar 'title_length':\n",
        "# Calcula la longitud de palabras para CADA título del DataFrame completo.\n",
        "data['title_length'] = data['title'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Calcular el Promedio Agrupado:\n",
        "\n",
        "avg_title = data.groupby('label_names')['title_length'].mean().reset_index(name='avg title length')\n",
        "\n",
        "\n",
        "# --- 2. Generación de los 3 Gráficos de Comparación ---\n",
        "\n",
        "# Configurar la figura: Crea una figura con 3 subgráficos en una sola fila (ncols=3).\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(15, 5)) # Aumentamos el tamaño para mejor visualización\n",
        "\n",
        "\n",
        "# Gráfico 1: Distribución de Títulos Falsos (ax1)\n",
        "\n",
        "ax1 = sns.histplot(fake_title, ax=ax1, bins=6, color='orangered', kde=True)\n",
        "ax1.set_xlim(0, 24) # Enfoca el eje X en el rango más común de palabras.\n",
        "ax1.set_xlabel('N° Palabras')\n",
        "ax1.set_title(\"N° Palabras (Títulos de Fake News)\", fontsize=12)\n",
        "\n",
        "\n",
        "# Gráfico 2: Distribución de Títulos Reales (ax2)\n",
        "\n",
        "ax2 = sns.histplot(real_title, ax=ax2, bins=15, color='royalblue', kde=True)\n",
        "ax2.set_xlim(0, 30) # Enfoca el eje X en el rango más común de palabras.\n",
        "ax2.set_xlabel('N° Palabras')\n",
        "ax2.set_title(\"N° Palabras (Título Noticia Real)\", fontsize=12)\n",
        "\n",
        "\n",
        "# Gráfico 3: Comparación del Promedio (ax3)\n",
        "\n",
        "ax3 = sns.barplot(data=avg_title, x='label_names', y='avg title length', ax=ax3, hue='label_names', palette={'fake': 'orangered', 'real': 'royalblue'}, legend=False)\n",
        "ax3.set_title(\"Promedio N° Palabras (Real vs Fake)\", fontsize=12)\n",
        "ax3.set_xlabel('Categoría')\n",
        "ax3.set_ylabel('Promedio de Palabras')\n",
        "\n",
        "# Añadir etiquetas de valor exacto encima de cada barra\n",
        "for index, row in avg_title.iterrows():\n",
        "    ax3.text(index, row['avg title length'] + 0.5, f\"{row['avg title length']:.2f}\", color='black', ha=\"center\")\n",
        "\n",
        "\n",
        "# Ajuste Final y Mostrar\n",
        "plt.tight_layout() # Ajusta automáticamente los subgráficos para evitar superposiciones.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdLhCtoQnC-Y"
      },
      "source": [
        "Estamos previsualizando si la longitud del título es, por sí misma, una característica predictiva de si una noticia es falsa o real.\n",
        "Si comparamos los titulos de noticias falsas la gran mayoria esta cercana a 11, mientras que en las noticias realeses más cercana a 13. Los titulos de noticias reales suelen tenen titulos más largos, en promedio 2 palabras más."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLFwkvmYn5_5"
      },
      "source": [
        "##2.3 Mapa de palabras más frecuentes en titulos reales y falsos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS_saLW_n5eK"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "text_fake = ' '.join(data.loc[data.labels == 0]['title'])\n",
        "text_real = ' '.join(data.loc[data.labels == 1]['title'])\n",
        "\n",
        "wordcloud_fake = WordCloud().generate(text_fake)\n",
        "wordcloud_real = WordCloud().generate(text_real)\n",
        "\n",
        "fig, (ax1,ax2) = plt.subplots(ncols=2,figsize=(12,6))\n",
        "\n",
        "ax1.imshow(wordcloud_fake)\n",
        "ax1.axis(\"off\")\n",
        "ax1.set_title(\"Nube Titulos en Fake News\",fontsize=20)\n",
        "\n",
        "ax2.imshow(wordcloud_real)\n",
        "ax2.axis(\"off\")\n",
        "ax2.set_title(\"Nube de TItulos en Noticias Reale\",fontsize=20)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIqbP8WQoLuR"
      },
      "source": [
        "# 3 . Procesamiento de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOG3TH2nHwFs"
      },
      "source": [
        "## 3.1 Limpieza de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X-LYTEEHzha"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def clean_text(text):\n",
        "    # 1. Convertir a minúsculas\n",
        "    text = str(text).lower()\n",
        "    # 2. Quitar puntuación\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # 3. Quitar números\n",
        "    text = re.sub(r'\\d+', ' ', text)\n",
        "    # 4. Quitar espacios extra y saltos de línea\n",
        "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
        "    return text.strip()\n",
        "\n",
        "# Aplicar la limpieza y crear las nuevas columnas\n",
        "data['title_cleaned'] = data['title'].apply(clean_text)\n",
        "data['text_cleaned'] = data['text'].apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHSOdJpHKCjM"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScyMf6UBIVAD"
      },
      "source": [
        "## 3.2 Analisis de Balance de Clases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik5JDT_wIO3L"
      },
      "outputs": [],
      "source": [
        "#Replicamos nuestro balance de clases:\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Mapeo de Etiquetas Legibles\n",
        "news_map = {1:'real', 0:'fake'}\n",
        "data['label_names'] = data['labels'].map(news_map)\n",
        "\n",
        "# 2. Visualizar la distribución\n",
        "plt.figure(figsize=(8, 6))\n",
        "# El histplot cuenta la frecuencia de cada etiqueta\n",
        "sns.histplot(data=data, x='label_names', hue='label_names', palette=['skyblue', 'salmon'], legend=False)\n",
        "plt.title('Distribución de Clases Objetivo (Fake vs Real)', fontsize=18)\n",
        "plt.xlabel('Clase', fontsize=12)\n",
        "plt.ylabel('Conteo', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show() #\n",
        "\n",
        "# Conteo numérico\n",
        "print(\"\\nConteo de clases:\")\n",
        "print(data['label_names'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No se ve un desbalance significativo."
      ],
      "metadata": {
        "id": "XBnjfuHOwVdG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1DMkYvQIg17"
      },
      "source": [
        "## 3.3 Analisis de Longitud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1L6qytJIl9q"
      },
      "outputs": [],
      "source": [
        "# 1. Calcular la longitud de cada título (en número de palabras)\n",
        "data['title_length'] = data['title_cleaned'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# 2. Visualizar la distribución de longitudes\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=data, x='title_length', bins=50, kde=True)\n",
        "plt.title('Distribución de Longitud de Títulos', fontsize=18)\n",
        "plt.xlabel('Número de palabras en el título')\n",
        "plt.ylabel('Frecuencia')\n",
        "\n",
        "# Establecer un límite de 50 palabras para ver mejor el cuerpo principal de la distribución\n",
        "plt.xlim(0, 50)\n",
        "\n",
        "# Calcular el percentil 90 para definir un MAX_LEN óptimo\n",
        "p90 = data['title_length'].quantile(0.90)\n",
        "plt.axvline(p90, color='r', linestyle='--', label=f'Percentil 90 ({int(p90)} palabras)')\n",
        "plt.legend()\n",
        "plt.show() #\n",
        "\n",
        "# Usar el percentil 90 para definir el MAX_LEN\n",
        "MAX_LEN_SUGERIDO = int(p90)\n",
        "print(f\"\\nMAX_LEN sugerido (Percentil 90): {MAX_LEN_SUGERIDO} palabras.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUTrFwc7KkSb"
      },
      "source": [
        "Al usar P90 de la disribución total, nos aseguramos de que el 90% de todos los titulos no necsite truncarse, logrando el mejor equilibrio entre perdidas de datos y eficiencia. Sin embargo dentro de esta distribución buscamos el MAX_LEN que nos recomienda el modelo, que son 16 palabras. El MAX_LEN es un metodo utilizado en modelo Keras que definirá como un parametro fijo el numero de tokens a utilizar. Por lo que si le faltan tokens para completar los 16, se los agregara. Si utilizaramos el 90% sería un max len cercano a 26 tokens, lo cual computacionalmente sería muy costoso.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque el 75% de nuestros datos se extendía hasta 21 tokens y el $90\\%$ hasta 26 tokens, el valor de $\\mathbf{MAX\\_LEN}$ fue establecido en $\\mathbf{16}$ tokens, basándose en la mediana de los datos ($16.50$ tokens). Esta decisión se tomó para maximizar la eficiencia computacional y reducir el tiempo de entrenamiento, bajo el supuesto de que la información más crítica para la clasificación de un titular se encuentra concentrada en los primeros 16 tokens. El alto rendimiento final del modelo ($\\approx 91\\%$) valida esta estrategia de compromiso."
      ],
      "metadata": {
        "id": "Th7v6vgtzDI4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAi4s5nSK1kC"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Asumimos que 'title_length' y 'label_names' ya existen de los pasos anteriores\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Gráfico de violín: Muestra la densidad de la distribución por cada clase.\n",
        "sns.violinplot(x='label_names', y='title_length', data=data, palette=['salmon', 'skyblue'])\n",
        "plt.title('Distribución de Longitud de Títulos por Clase', fontsize=18)\n",
        "plt.xlabel('Clase de Noticia', fontsize=12)\n",
        "plt.ylabel('Número de palabras en el título', fontsize=12)\n",
        "plt.ylim(0, 40) # Limitar el eje Y para una mejor visualización de los datos principales\n",
        "plt.show() #\n",
        "\n",
        "# Estadísticas numéricas de confirmación\n",
        "print(\"\\nEstadísticas de Longitud Media por Clase:\")\n",
        "print(data.groupby('label_names')['title_length'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoyJCNm6LJWq"
      },
      "source": [
        "El MAX_LEN de 16 palabras es ahora aún más robusto:\n",
        "- Cubre el 75% de los títulos reales y casi la totalidad de los títulos falsos sin truncamiento.\n",
        "- El 90% del conjunto total es cubierto, garantizando una alta eficiencia de entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aligual que vimos anteriormente pero desde otra perspectiva graficamente , el análisis de la longitud de los títulos revela una diferencia consistente: los titulares de noticias reales son significativamente más largos (Media $\\mathbf{12.96}$) que los de noticias falsas (Media $\\mathbf{10.69}$). Esta diferencia de $\\approx 2$ a $3$ palabras y la mayor variabilidad en la longitud de los títulos reales, sugieren que la longitud es un predictor débil, pero auxiliar que el modelo puede utilizar para la clasificación, además de los patrones semánticos.\n",
        "\n",
        "La distribución de la longitud de los títulos está demasiado mezclada para clasificar con confianza. La superposición hace que la longitud no sea decisiva.Se clasifica como predictor débil porque, a pesar de la diferencia en la media, existe una alta superposición entre las distribuciones de longitud de las clases. El núcleo de la clasificación reside en los patrones semánticos (que detecta el LSTM) y no en métricas superficiales como la longitud, lo cual sería insuficiente por sí solo para alcanzar una alta precisión."
      ],
      "metadata": {
        "id": "JF8vpMC21Dv-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OpOhGI0FTjn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Inicialización del Tokenizer\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "    # 1. Tamaño del Vocabulario:\n",
        "    # Indica el número máximo de palabras a considerar, basado en su frecuencia. Si se usa None, incluye todas las palabras únicas\n",
        "    num_words=None,\n",
        "\n",
        "    # 2. Filtros de Limpieza:\n",
        "    # Define los caracteres de puntuación que deben ser eliminados de los textos\n",
        "    filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n',\n",
        "\n",
        "    # 3. Normalización:\n",
        "    # Convierte todo el texto a minúsculas, como el mismo token. Es vital para la consistencia.\n",
        "    lower=True,\n",
        "\n",
        "    # 4. Separador de Palabras:\n",
        "    # Especifica que las palabras deben separarse por espacios (' ').\n",
        "    split=' ',\n",
        "\n",
        "    # 5. Nivel de Tokenización:\n",
        "    # False indica que la unidad de tokenización es la PALABRA completa, no el carácter.\n",
        "    char_level=False,\n",
        "\n",
        "    # 6. Tokens Desconocidos (OOV):\n",
        "    # Especifica el token que se debe usar para reemplazar las palabras que no se encontraron en el vocabulario construido (las palabras raras).\n",
        "    # Usar None significa que las palabras raras simplemente se ignoran. Este valor debería ser 'oov_token=<UNK>'.\n",
        "    oov_token=None,\n",
        "\n",
        "    # 7. Analizador:\n",
        "    # Parámetro avanzado que se deja en None para usar la configuración de filtro estándar.\n",
        "    analyzer=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ddv_O1kQLaxK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Parámetros definidos:\n",
        "MAX_LEN = 16        # Longitud máxima de las secuencias (definida por el Percentil 90)\n",
        "MAX_WORDS = 10000   # Número máximo de palabras a considerar en el vocabulario de Keras\n",
        "\n",
        "# --- A. División de Datos ---\n",
        "# Usamos el 80% para entrenamiento y 20% para prueba.\n",
        "# Usamos las columnas limpias (X) y las etiquetas (y).\n",
        "X = data['title_cleaned'].values\n",
        "y = data['labels'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f\"Tamaño de Entrenamiento: {len(X_train)} | Tamaño de Prueba: {len(X_test)}\")\n",
        "\n",
        "# --- B. Inicialización y Ajuste del Tokenizer ---\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<unk>\")\n",
        "# fit_on_texts solo debe ejecutarse en los datos de entrenamiento para evitar el sesgo\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# --- C. Conversión a Secuencias Numéricas ---\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# --- D. Aplicación de Padding ---\n",
        "# Convierte las secuencias a la longitud uniforme de MAX_LEN (16)\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "\n",
        "# --- E. One-Hot Encoding (OHE) de Etiquetas ---\n",
        "# Necesario para la función de pérdida 'categorical_crossentropy'\n",
        "y_train_ohe = to_categorical(y_train)\n",
        "y_test_ohe = to_categorical(y_test)\n",
        "\n",
        "print(f\"\\nForma de los datos de entrenamiento (Padded): {X_train_padded.shape}\")\n",
        "print(f\"Forma de las etiquetas de entrenamiento (OHE): {y_train_ohe.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz7wx3tRLv2T"
      },
      "source": [
        "Este código toma tus datos limpios, los divide en conjuntos de entrenamiento y prueba, y los convierte en el formato numérico de longitud uniforme que Keras necesita."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# --- A. Preparación de Datos ---\n",
        "# Usamos las variables limpias (X) y las etiquetas (y) de la sesión anterior\n",
        "X = data['title_cleaned'].values\n",
        "y = data['labels'].values\n",
        "\n",
        "# Dividir los datos (80% entrenamiento, 20% prueba)\n",
        "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "print(\"Datos divididos para el modelo de Línea Base.\")\n",
        "\n",
        "# --- B. Definición del Pipeline ---\n",
        "# El Pipeline aplica los pasos en orden:\n",
        "# 1. TfidfVectorizer: Convierte el texto en vectores numéricos de importancia.\n",
        "# 2. LogisticRegression: El modelo de clasificación simple y lineal.\n",
        "\n",
        "baseline_model = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=10000, stop_words='english')),\n",
        "    ('clf', LogisticRegression(max_iter=500))\n",
        "])\n",
        "\n",
        "# --- C. Entrenamiento y Predicción ---\n",
        "baseline_model.fit(X_train_base, y_train_base)\n",
        "predictions_base = baseline_model.predict(X_test_base)\n",
        "\n",
        "# --- D. Evaluación ---\n",
        "acc_base = accuracy_score(y_test_base, predictions_base)\n",
        "f1_base = f1_score(y_test_base, predictions_base)\n",
        "\n",
        "print(\"\\n--- Resultados del Modelo de Línea Base ---\")\n",
        "print(f\"Precisión (Accuracy) de Línea Base: {acc_base:.4f}\")\n",
        "print(f\"Puntaje F1 de Línea Base: {f1_base:.4f}\")"
      ],
      "metadata": {
        "id": "7F5iFElZaGw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de avanzar con el modelo LSTM, conviene saber que resultados nos da con un modelo simple (sin TOkeinizacion Keras y el Embedding), solo ua regresion logistica que se entrena. EM estae caso nos entrega"
      ],
      "metadata": {
        "id": "u061pAtyapOH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XphBaPz7GY4Q"
      },
      "source": [
        "# 4 . Definición Modelo Keras (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCPo_aCBL5F7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "# Dimensiones clave:\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "EMBEDDING_DIM = 100\n",
        "MAX_LEN = 16\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LEN),\n",
        "    LSTM(64),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# FORZAR LA CONSTRUCCIÓN DEL MODELO:\n",
        "# La forma esperada del input es (None, MAX_LEN), donde None es el batch size.\n",
        "model.build(input_shape=(None, MAX_LEN))\n",
        "\n",
        "print(\"\\n--- Resumen del Modelo LSTM (Corregido) ---\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3_sFUCwMzei"
      },
      "source": [
        "El modelo toma tus títulos, los convierte a números (Embedding), aprende el contexto de esos números (LSTM), y finalmente, clasifica el contexto en una de dos categorías (Dense de 2 neuronas). El modelo está listo y correctamente estructurado para ser entrenado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUqvzqjcM4xS"
      },
      "source": [
        "## 4.2 Entrenamiento con Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoxjaWxlM9qs"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Criterio de Evaluación: Determina el número de épocas a usar.\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',           # Monitorear la pérdida en el conjunto de validación\n",
        "    patience=10,                   # Esperar 10 épocas sin mejora en val_loss antes de detener\n",
        "    restore_best_weights=True     # Restaurar los pesos del mejor punto de val_loss\n",
        ")\n",
        "\n",
        "NUM_EPOCHS_MAX = 20 # Definimos un máximo para no correr infinitamente\n",
        "\n",
        "print(\"Iniciando entrenamiento del modelo LSTM...\")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train_ohe,\n",
        "    epochs=NUM_EPOCHS_MAX,\n",
        "    batch_size=64, # Un batch size de 64 o 128 es común para texto\n",
        "    validation_split=0.1, # Usar el 10% de los datos de entrenamiento para la validación\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n--- Entrenamiento Finalizado ---\")\n",
        "# La longitud del historial de pérdida nos da el número real de épocas entrenadas\n",
        "epochs_trained = len(history.history['loss'])\n",
        "print(f\"El modelo se entrenó por {epochs_trained} épocas antes de la detención temprana.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aovbeJTFNWXq"
      },
      "source": [
        "Para determinar el número óptimo de épocas, se empleó la técnica de Detención Temprana EarlyStopping, monitoreando la Pérdida de Validación (val_loss).\n",
        "Punto Óptimo: La Época 2 presenta la pérdida de validación más baja ($\\mathbf{0.2273}$) y una precisión de validación muy alta ($\\mathbf{0.9073}$). Este es el punto donde el modelo demostró la mejor capacidad de generalización a datos no vistos.\n",
        "\n",
        "Detección de Overfitting: A partir de la Época 3, comienza el sobreajuste (overfitting). La pérdida de validación (val_loss) se dispara ($0.2400 \\rightarrow 0.2871 \\rightarrow 0.3723$), mientras que la precisión de validación (val_accuracy) comienza a descender de forma constante ($0.9059 \\rightarrow 0.9040 \\rightarrow 0.9008$).\n",
        "\n",
        "Mientras que la precisión en el entrenamiento sigue aumentando hasta $\\approx 99\\%$, la capacidad predictiva del modelo en datos nuevos está empeorando progresivamente.\n",
        "\n",
        "Conclusión: Por lo tanto, el modelo que debe seleccionarse para la producción es el que contiene los pesos guardados al final de la Época 2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq4bc3EINgka"
      },
      "source": [
        "## 4.3 Precision y Perdida Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY8PNTHpM4By"
      },
      "outputs": [],
      "source": [
        "# Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test_ohe, verbose=0)\n",
        "\n",
        "print(f\"\\n--- Resultados del Modelo LSTM en el Conjunto de Prueba ---\")\n",
        "print(f\"Pérdida (Loss) Final: {loss:.4f}\")\n",
        "print(f\"Precisión (Accuracy) Final: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FN2iCRSN7Sa"
      },
      "source": [
        "Precisión (Accuracy) Final ($\\mathbf{91.18\\%}$) Indica que el modelo clasificó correctamente el 90.57% de los títulos de noticias que nunca había visto durante el entrenamiento.\n",
        "  \n",
        "Pérdida (Loss) Final ($\\mathbf{22.64\\%}$) Representa el \"costo\" o el error promedio del modelo en el conjunto de prueba. Un valor bajo (cercano a cero) es bueno."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh2u6l86NmHQ"
      },
      "source": [
        "## 4.4 Grafico de Perdida y Precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xyxc9fDtPIUT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Acceder al historial de entrenamiento (history)\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "accuracy_values = history_dict['accuracy']\n",
        "val_accuracy_values = history_dict['val_accuracy']\n",
        "\n",
        "# El modelo se entrenó por 4 épocas (indices 0, 1, 2, 3)\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# --- Gráfico de Pérdida (Loss) ---\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, loss_values, 'bo-', label='Pérdida de Entrenamiento')\n",
        "plt.plot(epochs, val_loss_values, 'ro-', label='Pérdida de Validación')\n",
        "plt.title('Pérdida a través de las Épocas')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# --- Gráfico de Precisión (Accuracy) ---\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, accuracy_values, 'bo-', label='Precisión de Entrenamiento')\n",
        "plt.plot(epochs, val_accuracy_values, 'ro-', label='Precisión de Validación')\n",
        "plt.title('Precisión a través de las Épocas')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Precisión')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los gráficos de entrenamiento demuestran que el modelo LSTM sobreajusta rápidamente. La divergencia entre la pérdida de entrenamiento y la pérdida de validación (la curva azul sube a partir de la Época 3) indica que el modelo memoriza el ruido en los datos de entrenamiento. Por lo tanto, el punto óptimo de generalización y la mejor versión del modelo se encuentran en la Época 2, donde la pérdida de validación es mínima ($\\mathbf{0.2273}$)."
      ],
      "metadata": {
        "id": "TcpqV_1hJSU8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPPN6Xw3PRsS"
      },
      "source": [
        "## 4.5 Prueba con Noticia Externa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1p2MG5R1PRG7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Definición de la función clean_text (necesaria para limpiar la entrada)\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = re.sub(r'\\d+', ' ', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
        "    return text.strip()\n",
        "\n",
        "# Asumimos que MAX_LEN y tokenizer están definidos de los pasos anteriores\n",
        "MAX_LEN = 16\n",
        "\n",
        "def predict_single_news(title, model, tokenizer, max_len=MAX_LEN):\n",
        "    cleaned_title = clean_text(title)\n",
        "\n",
        "    # 1. Tokenizar y convertir a secuencia\n",
        "    seq = tokenizer.texts_to_sequences([cleaned_title])\n",
        "\n",
        "    # 2. Aplicar Padding\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "    # 3. Predicción\n",
        "    prediction = model.predict(padded_seq, verbose=0)\n",
        "\n",
        "    # np.argmax devuelve el índice de la clase (0 o 1) con la probabilidad más alta\n",
        "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "    # Mapa inverso: Asumimos 0=Falsa, 1=Verdadera\n",
        "    result_map = {0: \"FALSA\", 1: \"VERDADERA\"}\n",
        "    result = result_map[predicted_class]\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Título: '{title}'\")\n",
        "    print(f\"Probabilidad de ser {result}: {np.max(prediction):.4f}\")\n",
        "    print(f\"PREDICCIÓN FINAL: {result}\")\n",
        "    return result\n",
        "\n",
        "# --- Prueba 1: Noticia Falsa (Breitbart) ---\n",
        "# URL: https://www.breitbart.com/politics/2016/09/10/exposed-fbi-director-james-comeys-clinton-foundation-connection/\n",
        "fake_title = \"Exposed: FBI Director James Comey’s Clinton Foundation Connection\"\n",
        "print(\"\\n--- PRUEBA DE NOTICIA FALSA ---\")\n",
        "predict_single_news(fake_title, model, tokenizer)\n",
        "\n",
        "# --- Prueba 2: Noticia Verdadera (Washington Post) ---\n",
        "# URL: https://www.washingtonpost.com/sports/2022/11/14/world-cup-female-referee-kathryn-nesbitt/\n",
        "real_title = \"The World Cup will feature female referees for the first time.\"\n",
        "print(\"\\n--- PRUEBA DE NOTICIA VERDADERA ---\")\n",
        "predict_single_news(real_title, model, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtqVzX-yiBQV"
      },
      "source": [
        "Modelo calsifico ambas noticias como verdadera, siendo la primera Falsa. Por ende fallo en la clasificación.\n",
        "\n",
        "Posibles causas:\n",
        "\n",
        "- Ausencia de Embedding: Es muy probable que el título de Breitbart contenga palabras que no estaban en las 10,000 palabras más comunes.\n",
        "\n",
        "- Si el modelo ve muchos tokens <unk>, le cuesta hacer la clasificación correcta, y se apoya en el patrón más común, la clase VERDADERA.\n",
        "\n",
        "- Aunque MAX_LEN=16 es óptimo, el modelo LSTM no es tan bueno como BERT para capturar el significado contextual sutil del lenguaje de confrontación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHkekiFtPm8C"
      },
      "source": [
        "# 5 . PYtorch/BERT/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmG37NWijPPa"
      },
      "source": [
        "## 5.1 Carga de Herramientas y Tokenizacion BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGlOwdiNqSm5"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import Dataset, DatasetDict\n",
        "import torch\n",
        "\n",
        "# 1. Parámetros y Checkpoint de BERT\n",
        "MODEL_CKPT = \"bert-base-uncased\"\n",
        "MAX_LEN_BERT = 32 # Usamos el MAX_LEN estándar de BERT, aunque nuestros títulos son más cortos\n",
        "\n",
        "# Cargar el tokenizador de BERT\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CKPT)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_val_df, test_df = train_test_split(data[['title_cleaned', 'labels']].rename(columns={'title_cleaned': 'text', 'labels': 'label'}),\n",
        "                                         test_size=0.2,\n",
        "                                         random_state=42)\n",
        "\n",
        "train_df, val_df = train_test_split(train_val_df,\n",
        "                                    test_size=0.1, # 10% of the train_val_df (~8% of total data) for validation\n",
        "                                    random_state=42)\n",
        "\n",
        "# Convertimos tus DataFrames limpios a DatasetDict\n",
        "dataset = DatasetDict({\n",
        "    'train': Dataset.from_pandas(train_df, preserve_index=False),\n",
        "    'test': Dataset.from_pandas(test_df, preserve_index=False),\n",
        "    'validation': Dataset.from_pandas(val_df, preserve_index=False)\n",
        "})\n",
        "\n",
        "# 2. Función de Tokenización para BERT\n",
        "def tokenize_function(examples):\n",
        "    # Tokeniza el texto, añade padding y truncamiento\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN_BERT)\n",
        "\n",
        "# Aplicar la función de tokenización a todo el dataset\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Seleccionamos las columnas relevantes para el entrenamiento y cambiamos el tipo de dato de la etiqueta a PyTorch tensor\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "\n",
        "print(\"Dataset tokenizado con BERT y listo para PyTorch.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Cv3jjjjjLi"
      },
      "source": [
        "## 5.2 Configuración del Modelo Bert y LorA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwUDsC8AjiJs"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# Definimos las etiquetas (0 y 1)\n",
        "label2id = {'fake': 0, 'real': 1}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "# Configuración y Carga del Modelo Base (PyTorch)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "config = AutoConfig.from_pretrained(MODEL_CKPT, num_labels=2, label2id=label2id, id2label=id2label)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_CKPT, config=config).to(device)\n",
        "\n",
        "# --- Configuración LoRA ---\n",
        "# Usamos un rango (r) y un alpha (lora_alpha) mayores para darle más poder al fine-tuning.\n",
        "peft_config = LoraConfig(\n",
        "    task_type=\"SEQ_CLS\",\n",
        "    r=32,                  # Rango: Mayor capacidad de aprendizaje\n",
        "    lora_alpha=64,         # Factor de escalado\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"query\", \"key\", \"value\"], # Aplicamos LoRA a las matrices de Atención\n",
        ")\n",
        "\n",
        "# Aplicar LoRA al modelo BERT\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsNTchf5jm_J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Definición de la función de métricas\n",
        "def compute_metrics(p):\n",
        "    # p es un objeto EvalPrediction (contiene predicciones y etiquetas reales)\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    # Tomamos el índice con la probabilidad más alta para obtener la predicción (0 o 1)\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Usamos F1-Score (importante para tareas con potencial desbalance) y Accuracy\n",
        "    f1 = f1_score(p.label_ids, preds, average='binary')\n",
        "    acc = accuracy_score(p.label_ids, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1}\n",
        "\n",
        "# Parámetros de Entrenamiento (CORREGIDOS y MODIFICADOS)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert_lora_results\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "\n",
        "    # --- MODIFICACIÓN CLAVE ---\n",
        "    # Establece que no debe reportar métricas a ninguna plataforma (equivale a Opción 3)\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# Inicializar el Trainer\n",
        "trainer = Trainer(\n",
        "    model=model, # Modelo BERT con LoRA\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Entrenar el modelo\n",
        "print(\"\\nIniciando entrenamiento del Punto Extra (BERT/LoRA)...\")\n",
        "# El entrenamiento iniciará sin pedir ninguna opción.\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lJ_Xwa-1RDA"
      },
      "source": [
        "- Pérdida de Validación $\\mathbf{23\\%}$\n",
        "- Precisión $\\mathbf{91\\%}$\n",
        "- F1-Score $\\mathbf{90\\%}$\n",
        "\n",
        "El modelo BERT/LoRA es marginalmente más preciso ($91\\%$) que el LSTM ($90.57\\%$). Lo más importante es que, al ser un modelo Transformer, debería ser mucho mejor para manejar el contexto sutil y, por lo tanto, debería corregir el error de clasificación de la noticia falsa que falló el LSTM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EsPyNTEPoAb"
      },
      "source": [
        "## 5.3 Pueba de Noticias Flasa con Bert/LoRa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np_UvzEKPnHn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import string\n",
        "\n",
        "# Asumimos que 'trainer' y 'tokenizer' ahora están definidos en tu memoria de sesión\n",
        "# El modelo entrenado se encuentra en trainer.model\n",
        "# El tokenizador de BERT se encuentra en 'tokenizer'\n",
        "\n",
        "# Parámetros y Títulos\n",
        "MAX_LEN = 32 # Usamos el MAX_LEN de BERT\n",
        "fake_title_fail = \"Exposed: FBI Director James Comey’s Clinton Foundation Connection\"\n",
        "real_title_pass = \"The World Cup will feature female referees for the first time.\"\n",
        "\n",
        "def predict_with_bert(title, trainer_model, tokenizer_bert, max_len=MAX_LEN):\n",
        "    # 1. Tokenizar la entrada\n",
        "    inputs = tokenizer_bert(title, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_len)\n",
        "\n",
        "    # 2. Mover la entrada al dispositivo\n",
        "    # Intenta mover al mismo dispositivo que el modelo (esto es robusto)\n",
        "    device = next(trainer_model.parameters()).device\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # 3. Realizar la predicción\n",
        "    with torch.no_grad():\n",
        "        outputs = trainer_model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    # Aplicar softmax para obtener probabilidades\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "    predicted_class_id = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    # 0 es Falsa, 1 es Verdadera\n",
        "    result_map = {0: \"FALSA\", 1: \"VERDADERA\"}\n",
        "    predicted_label = result_map[predicted_class_id]\n",
        "    confidence = probabilities[0][predicted_class_id].item()\n",
        "\n",
        "    return predicted_label, confidence\n",
        "\n",
        "# --- PRUEBA FINAL CON BERT/LoRA ---\n",
        "print(\"\\n--- RE-EVALUACIÓN DEL TÍTULO FALLIDO CON BERT/LoRA ---\")\n",
        "# Usamos trainer.model para obtener el modelo entrenado\n",
        "pred_fake, conf_fake = predict_with_bert(fake_title_fail, trainer.model, tokenizer)\n",
        "print(f\"Título: '{fake_title_fail}'\")\n",
        "print(f\"PREDICCIÓN BERT/LoRA: {pred_fake} (Confianza: {conf_fake:.4f})\")\n",
        "print(f\"Resultado Esperado: FALSA\")\n",
        "\n",
        "print(\"\\n--- PRUEBA DE CONTROL ---\")\n",
        "pred_real, conf_real = predict_with_bert(real_title_pass, trainer.model, tokenizer)\n",
        "print(f\"Título: '{real_title_pass}'\")\n",
        "print(f\"PREDICCIÓN BERT/LoRA: {pred_real} (Confianza: {conf_real:.4f})\")\n",
        "print(f\"Resultado Esperado: VERDADERA\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"El modelo BERT/LoRA logró una precisión de validación ligeramente superior ($90.91\\%$) que el LSTM. Sin embargo, falló categóricamente en las pruebas de generalización externa, incluso en el caso de control (clasificando una noticia real como falsa). Esto evidencia que, a pesar de la alta métrica, el modelo sufre de un severo sesgo de generalización, posiblemente debido a datos de entrenamiento temáticamente limitados o a la agresiva optimización para F1-Score, lo que hizo que el modelo fuera demasiado cauteloso o demasiado agresivo con la clase minoritaria.\""
      ],
      "metadata": {
        "id": "C1GrIYvmUg8v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UPpz3hdJUhQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy6F4hWSpkwU"
      },
      "source": [
        "# Parte 2\n",
        "Se acerca el fin de año y con ello la necesidad de realizar los balances generales, estados financieros, etc. Una empresa te contrata para capturar manualmente todos sus recibos de ventas, solo que hay un pequeño problema: todos están hechos a mano, por lo que sería muy tardado ver recibo tras recibo y capturarlos de forma manual.\n",
        "\n",
        "Sin embargo, recuerdas que aprendiste acerca de las redes neuronales convolucionales. Por ello, decides hacer un modelo que afronte este problema con Inteligencia Artificial y que convierta la escritura a mano en caracteres.\n",
        "\n",
        "Tienes el *dataset* de dígitos escritos a mano de Mnist a tu disposición:\n",
        "https://www.tensorflow.org/datasets/catalog/mnist , que puedes invocar de esta manera:\n",
        "\n",
        "\n",
        "```python\n",
        "from tensorflow import keras\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "```\n",
        "\n",
        "## Criterios de evaluación\n",
        "- Entrena el modelo utilizando Tensorflow y todas las capas que creas necesarias. Explica por qué elegiste esas capas. Si no hay explicación, se invalida un punto (2 puntos).\n",
        "- Grafica la evolución de la pérdida y la precisión del entrenamiento y genera un conjunto de 10 predicciones con los mismos datos del *dataset* (2 puntos).\n",
        "\n",
        "\n",
        "¡Éxito! Te vemos en el contenido del siguiente módulo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFZObLFbg3S7"
      },
      "source": [
        "## Importar Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7XdgC3cg2oz"
      },
      "outputs": [],
      "source": [
        "## Paso 1: Importar librerías necesarias\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential # Importar Sequential\n",
        "from keras.layers import Conv2D, Dropout, MaxPooling2D, Flatten, Dense\n",
        "from keras.utils import to_categorical # Para one-hot encoding\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4icQsRNcfod5"
      },
      "source": [
        "# Cargar Data Set de MNSIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaoPWGrRgq4a"
      },
      "outputs": [],
      "source": [
        "## Paso 2: Cargar el dataset sobre imágenes de ropa\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Mostrar dimensiones del dataset\n",
        "print(f\"Dimensiones de train_images: {x_train.shape}\")  # (60000, 28, 28)\n",
        "print(f\"Dimensiones de test_images: {x_test.shape}\")  # (10000, 28, 28)\n",
        "\n",
        "# Mostrar una imagen de ejemplo\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualizar algunas imágenes de ejemplo\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(x_train[i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Etiqueta: {y_train[i]}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBBVkBA0ncVY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc3hc5BBlZxS"
      },
      "outputs": [],
      "source": [
        "x_train[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEy3M1rRluFr"
      },
      "source": [
        "Es una imagen en escala de grises (solo tiene dos dimensiones, $28 \\times 28$, sin una dimensión de canal RGB)\n",
        "Cada uno de los $28 \\times 28 = 784$ elementos dentro de esa matriz es un número entero entre 0 y 255, que representa la intensidad de brillo o valor del píxel en esa ubicación.\n",
        "En la matriz un 0, sería un pixel negro y un 255 un pixel blanco."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o-HYpJdnxKs"
      },
      "source": [
        "# Limpieza de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBzU-mvBnquc"
      },
      "outputs": [],
      "source": [
        "## Paso 3: Preprocesamiento de datos\n",
        "# Normalizar imágenes al rango [0,1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Añadir dimensión de canal (para TensorFlow necesita forma (28,28,1))\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "# Convertir etiquetas a one-hot encoding\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Verificar nueva forma de los datos\n",
        "print(f\"Forma de x_train después del preprocesamiento: {x_train.shape}\")  # (60000, 28, 28, 1)\n",
        "print(f\"Forma de y_train después del preprocesamiento: {y_train.shape}\")  # (60000, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWxcj3ylqSez"
      },
      "source": [
        "# Crear Red Neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD0gobvYqSHc"
      },
      "outputs": [],
      "source": [
        "## Paso 4: Creando nuestra red neuronal convolucional (CNN)\n",
        "model = Sequential()\n",
        "\n",
        "# Capa convolucional con padding='valid' (sin padding, la salida será más pequeña)\n",
        "model.add(Conv2D(filters=64, kernel_size=2, padding='valid', activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Capa convolucional con padding='same' (mantiene tamaño de la salida)\n",
        "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Aplanar la imagen para conectarla a una capa densa\n",
        "model.add(Flatten())\n",
        "\n",
        "# Capa completamente conectada con 256 neuronas\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Capa de salida con 10 neuronas (una por categoría), activación softmax\n",
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTgwayQVCGNC"
      },
      "source": [
        "## Justificiación de Capas:\n",
        "\n",
        "1.   **Conv2D**: Es la primera capa que decidimos utilizar 64 kernels, es decir nucleos que realizan operaciones de convulación que utilizan caracteristicas y las identifica para detectar patrones. Basicamente una matriz que me entrega un vector de resultados con valores que me permite identificar patrones através de la función de maximización Relu, que es la más eficiente computacionalmente para este caso.\n",
        "2.   **MaxPooling2D**: Permite conservar solo la información más importante y elimina el ruido. Disminiuyendo a la mitad la dimensión espacial de la imagen, robustenciendo el modelo.\n",
        "\n",
        "3. **DropOut**: Es casi un seguro anti-trampa. En donde deja inoperativo un 30% de los filtros aleatoriamente, para que el modelo no depende de ningun filtro en especifico, previniendo el sobreajuste.\n",
        "\n",
        "Luego estas 3 capas se repiten, pero de manera de encontrar patrones mas complejos. Luego:\n",
        "\n",
        "4. **Flatten**: Transforma los daatos en una forma plana y de linea de numeros para que pueda ser procesado en la siguiente capa.\n",
        "\n",
        "5. **Dense**: Esta capa es de clasificación oculta, recibe la infromación de la capa Conv2D y MaxPooling2D y la conecta con 256 neuronas para realizar el proceso de multiplicarlas por un peso que aprendió, lo suma como un todo y lo corrige con un sesgo. Todo esto para encontrar la relación entre las caracteristicas y las posibles clases.\n",
        "\n",
        "Luego se prepara para el paso final de la prediccion, con una capa de salida de 10 neuronas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymMA1iOts12p"
      },
      "source": [
        "# Compilar y entrenar el Modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuDMvDW2s85S"
      },
      "source": [
        "## Compilar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhcDgrTPs02y"
      },
      "outputs": [],
      "source": [
        "## Paso 5: Compilando y entrenando el modelo\n",
        "# Compilar el modelo con pérdida de entropía cruzada categórica y optimizador RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5LSiTMuZ--b"
      },
      "source": [
        "Luego de hot-encoding, se utiliza el optimizador del Descenso de la Gradienteque que ajusta los pesos del modelo. Se elige porque es muy efectivo para redes no estacionarias y es conocido por converger rápidamente en problemas de visión por computadora."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS2s40ETtIiL"
      },
      "source": [
        "## Entrenar Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQd_20fbtK0T"
      },
      "outputs": [],
      "source": [
        "# Definir callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1, restore_best_weights=True)\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='CNN_AGJ.keras',\n",
        "                             monitor='val_loss',\n",
        "                             save_best_only=True,\n",
        "                             verbose=1)\n",
        "\n",
        "# Entrenar el modelo con los callbacks\n",
        "history = model.fit(x_train, y_train,\n",
        "                      batch_size=64,\n",
        "                      epochs=10,\n",
        "                      validation_split=0.2,\n",
        "                      callbacks=[early_stopping, checkpoint],\n",
        "                      verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M5RuLEAwFbe"
      },
      "source": [
        "# Evolución Perdida y Precisión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeFLmqTswBE_"
      },
      "outputs": [],
      "source": [
        "## Paso 6: Graficar la evolución del entrenamiento\n",
        "# Extraer historial de entrenamiento\n",
        "history_dict = history.history\n",
        "loss, val_loss = history_dict['loss'], history_dict['val_loss']\n",
        "accuracy, val_accuracy = history_dict['accuracy'], history_dict['val_accuracy']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "# Crear figura con 1 fila y 2 columnas\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Gráfico de pérdida\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, loss, 'o-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, '--', label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Evolución de la Pérdida')\n",
        "plt.xticks(epochs)\n",
        "plt.legend()\n",
        "\n",
        "# Gráfico de precisión\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, accuracy, 'o-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, '--', label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Evolución de la Precisión')\n",
        "plt.xticks(epochs)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGuUcMoLTuzD"
      },
      "source": [
        "\n",
        "El gráfico se divide en dos secciones que deben interpretarse juntas para un diagnóstico completo:\n",
        "\n",
        "1.\n",
        "Evolución de la Pérdida\n",
        "\n",
        "Pérdida de Entrenamiento (Línea Azul): Comienza alta (alrededor de 0.35) y cae de manera pronunciada hasta la época 4 (cerca de 0.08), estabilizándose a un valor muy bajo (cerca de 0.06) al final de la época 9. Esto indica que el modelo está aprendiendo a minimizar el error rápidamente. Lo que signfica que es muy eficiente en minimizar el error en los datos que ha visto.\n",
        "\n",
        "Pérdida de Validación (Línea Naranja): Comienza y se mantiene consistentemente más baja que la pérdida de entrenamiento (entre 0.04 y 0.05).Esto significa que  el modelo está generalizando excepcionalmente bien desde el principio.\n",
        "\n",
        "2.\n",
        "Evolución de la Precisión (Accuracy)\n",
        "\n",
        "Precisión de Entrenamiento (Línea Azul): Se mantiene muy alta y estable (alrededor de 0.978 a 0.980).\n",
        "\n",
        "Precisión de Validación (Línea Naranja): Es la métrica más importante y es consistentemente más alta y más errática que la precisión de entrenamiento (alrededor de 0.988 a 0.990).\n",
        "\n",
        "\n",
        "\n",
        "En conclusión:\n",
        "\n",
        "Existe una Convergencia Rápida: El modelo ha alcanzado un estado de alta precisión (cercana al 99%) en solo 9 épocas. Esto es muy eficiente y confirma que la arquitectura y la elección del optimizador (rmsprop) fueron adecuadas para el problema.\n",
        "\n",
        "Exsite una Generalización Confirmada: El hecho de que la Pérdida de Validación es más baja y la Precisión de Validación es más alta que sus contrapartes de entrenamiento indica que el modelo no tiene overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixLUGvF8yfvu"
      },
      "source": [
        "## Evaluar Modelo sobre Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCGQphYSyfcv"
      },
      "outputs": [],
      "source": [
        "## Paso 7: Evaluando sobre data de test\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(\"Pérdida en el conjunto de prueba:\", test_loss)\n",
        "print(\"Precisión en el conjunto de prueba:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abv89ItNRXmz"
      },
      "source": [
        "#¿Que tan útil es nuestro modelo para capturar los datos escritos a mano?\n",
        " El test_accuracy de 0.9883 es muy cercano al validation_accuracyde las últimas épocas de entrenamiento (que superó el 98%).\n",
        "\n",
        "Conclusión: Esto demuestra que el modelo no sufrió un sobreajuste significativo (overfitting). El modelo aprendió las características esenciales de los dígitos en lugar de memorizar el ruido de los datos de entrenamiento."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}